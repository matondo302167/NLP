{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d53d4c2",
   "metadata": {},
   "source": [
    "# Tâche 3 - Classification automatique de descriptions d'incidents\n",
    "\n",
    "Cette tâche vise à classifier de courts textes décrivant des incidents qui se sont produits sur des chantiers de construction. Pour chaque incident, on retrouve une étiquette qui correspond au type d’incident (0 à 8). \n",
    "\n",
    "Les objectifs de cette tâche sont: \n",
    "- de se familiariser avec la classification de texte\n",
    "- d'apprendre à utiliser les fonctions de base de scikit-learn\n",
    "- de comprendre comment représenter un texte sous la forme d'un sac de mots (*bag of words*)\n",
    "- de faire l'évaluation d'un modèle de classification avec un corpus de test\n",
    "- de tenter d'interpréter les résultats d'un modèle à l'aide des poids d'attributs. \n",
    "\n",
    "Pour la première partie, vous devez construire une fonction (*train_and_test_classifier*) qui entraîne un modèle (les options étant la régression logistique et le naïf bayésien) et en faire l'évaluation sur des données d'entraînement et des données de test. Vous devez également évaluer l'impact de la lemmatisation de mots sur la performance des classificateurs. Deux fichiers de textes sont disponibles pour mener votre expérimentation (voir Section 1). \n",
    "\n",
    "Pour la deuxième partie, tentez de déterminer à quoi correspond chacune des classes d’incident. Faites une analyse des poids des modèles pour proposer des étiquettes pour chacune des classes. Vous pouvez vous inspirer des notebooks disponibles sur le site du cours. Expliquez clairement comment vous êtes arrivé à vos conclusions. L’important ici est de dégager le thème principal à partir de vos observations et non pas de trouver la formulation exacte des étiquettes. Veuillez noter que certaines classes sont (très) difficiles à identifier. \n",
    "\n",
    "Merci de respecter les signatures des fonctions *train_and_test_classifier* et *load_incident_dataset*.\n",
    "\n",
    "Note sur la lemmatisation: Cette normalisation de texte nécessite l'utilisation d'un modèle qui repose sur l'apprentissage automatique. En conséquence, son temps d'exécution est plus long que le stemming. Si jamais cela ralentit trop vos expérimentations, il est possible de ne faire le traitement qu'une seule fois en sauvegardant les résultats après la première lemmatisation d'un fichier. Cela n'est toutefois pas exigé pour la remise de votre travail et ne sera pas évalué. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cb0b9",
   "metadata": {},
   "source": [
    "## Section 1 - Lecture des fichiers de données\n",
    "\n",
    "Voici les fichiers mis à votre disposition pour mener vos expérimentations. La fonction *load_incident_data* peut être utilisée pour lire les 2 fichiers (train et test). Rien à modifier dans cette section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7082859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_json_fn = \"./data/t3_train.json\"\n",
    "test_json_fn = \"./data/t3_test.json\"\n",
    "\n",
    "\n",
    "def load_incident_dataset(filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        incident_list = json.load(fp)\n",
    "    return incident_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aea833",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = load_incident_dataset(train_json_fn)\n",
    "print(\"Nombre d'incidents:\", len(train_list))\n",
    "print(\"\\nUn exemple:\\n\", train_list[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88755bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = load_incident_dataset(test_json_fn)\n",
    "print(\"Nombre d'incidents\", len(test_list))\n",
    "incident = test_list[10]\n",
    "print(\"\\nUne description d'incident:\", incident[\"text\"])\n",
    "print(\"\\nSon étiquette:\", incident[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a418049",
   "metadata": {},
   "source": [
    "## Section 2 - Entraînement et évaluation des modèles  \n",
    "\n",
    "Vous pouvez ajouter tout le code dont vous avez besoin pour l'entraînement. Merci de ne pas modifier la signature de la fonction d'entraînement et de bien expliquer votre démarche et vos résultats. N'oubliez pas de faire une recommandation de modèle. Vous pouvez ajouter des cellules au notebook si nécessaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb39cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38738d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer ici les librairies dont vous avez besoin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_and_test_classifier(train_fn, test_fn, model='NB', normalization='words'):\n",
    "    \"\"\"\n",
    "    :param train_fn et test_fn: les 2 fichiers utilisées pour entraîner et tester les classificateurs.\n",
    "    :param model: le type de classificateur. NB = Naive Bayes, LR = Régression logistique.\n",
    "    :param normalization: la nomralisation appliquée aux mots des descriptions\n",
    "                 - 'word': les mots des textes sans normalization.\n",
    "                 - 'lemma': les lemmes des mots obtenus par lemmatisation avec Spacy.\n",
    "    :return: un dictionnaire contenant 3 valeurs:\n",
    "                 - l'accuracy à l'entraînement (validation croisée)\n",
    "                 - l'accuracy sur le jeu de test\n",
    "                 - la matrice de confusion calculée par scikit-learn sur les données de test\n",
    "    \"\"\"\n",
    "\n",
    "    # Votre code...\n",
    "\n",
    "    \n",
    "\n",
    "    # Les résultats à retourner\n",
    "    results = dict()\n",
    "    results['accuracy_train'] = 0.9\n",
    "    results['accuracy_test'] = 0.8\n",
    "    results['confusion_matrix'] = None  # la matrice de confusion obtenue de Scikit-learn\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a126c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342af14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3f458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a9dbd2",
   "metadata": {},
   "source": [
    "## Section 3 - À quoi correspondent les classes? Explicabilité du modèle\n",
    "\n",
    "En utilisant les poids des modèles, tentez d'attribuer une signification aux différentes classes. Comme c'est une épreuve d'analyse de données, il est possible que certaines classes ne soient pas interprétables. Vous n'êtes pas tenu à l'impossible. L'important est d'utiliser ce qu'on observe dans les modèles pour fournir une explication.\n",
    "\n",
    "Vous pouvez ajouter tout le code et toutes les cellules dont vous avez besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abbe15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9d7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40076487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ffcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706eba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8518aab0",
   "metadata": {},
   "source": [
    "## Section 4 - Section réservée pour nos tests (ne pas modifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b8bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ab13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811c1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f9746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1912bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
